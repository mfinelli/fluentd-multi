@include "#{ENV['FLUENTD_SYSTEMD_CONF'] || 'systemd'}.conf"
@include "#{ENV['FLUENTD_PROMETHEUS_CONF'] || 'prometheus'}.conf"
@include kubernetes.conf
@include conf.d/*.conf

<match **>
  @type copy
  <store>
    @type cloudwatch_logs
    @id out_cloudwatch_logs
    log_group_name "#{ENV['LOG_GROUP_NAME']}"
    auto_create_stream true
    use_tag_as_stream true
    retention_in_days "#{ENV['RETENTION_IN_DAYS'] || 'nil'}"
    json_handler yajl # To avoid UndefinedConversionError
    log_rejected_request "#{ENV['LOG_REJECTED_REQUEST']}" # Log rejected request for missing parts
  </store>
  <store>
    @type loggly
    @id out_loggly
    @log_level info
    loggly_url "https://logs-01.loggly.com/bulk/#{ENV['LOGGLY_TOKEN']}/tag/#{ENV['LOGGLY_TAGS'] || 'fluentd'}/bulk"
  </store>
  <store>
    # docs: https://github.com/daichirata/fluent-plugin-gcs
    # this configuration relies on the nodes having permission to write on your gs bucket
    @type gcs
    @id out_gcs
    project "#{ENV['GCS_BUCKET_PROJECT']}"
    bucket "#{ENV['GCS_BUCKET_NAME']}"
    object_key_format %{path}%{time_slice}/%{hostname}/%{index}.%{file_extension}
    path logs/
    buffer_path /var/log/fluentd-buffers/gcs.buffer
    time_slice_format %Y/%m/%d
    time_slice_wait 10m
    utc
  </store>
</match>
